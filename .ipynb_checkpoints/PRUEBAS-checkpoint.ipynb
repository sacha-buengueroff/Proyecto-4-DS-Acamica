{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gross-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disturbed-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_lemm.csv') #CONTIENTEN NAN EN LA ULTIMA COLUMNA.\n",
    "df = pd.read_csv('palabras_estrellas_lemm.csv')\n",
    "data['review_title_body_lemma'] = data['review_title_body_lemma'].astype(str)\n",
    "data = data[data['review_title_body_lemma'] != \"nan\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-delta",
   "metadata": {
    "id": "YLkuIOx5Eh9C"
   },
   "outputs": [],
   "source": [
    "remover_1 = [\"producto\"] #para 1, 2, 3, 4 y 5\n",
    "remover_2 = ['bien', 'precio', 'gustar', 'mucho', 'esperar', 'quedar', 'comprar', 'funcionar', 'mal', 'llegar', 'calidad', 'sin', 'buen'] #para 2 y 3\n",
    "remover_3 = [\"bonito\"] #para 3\n",
    "remover_4 = [\"funcionar\"] #para 3 y 4\n",
    "\n",
    "filtro_2 = (data[\"stars\"] == 2) | (data[\"stars\"] == 3)\n",
    "filtro_3 = (data[\"stars\"] == 3)\n",
    "filtro_4 = (data[\"stars\"] == 3) | (data[\"stars\"] == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fatty-portland",
   "metadata": {
    "id": "cQREQ-_uG5Ui"
   },
   "outputs": [],
   "source": [
    "for palabra in remover_1:\n",
    "    data[\"review_title_body_lemma\"] = data[\"review_title_body_lemma\"].str.replace(palabra,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "embedded-question",
   "metadata": {
    "id": "KowJR1MUI-Pc"
   },
   "outputs": [],
   "source": [
    "for palabra in remover_2:\n",
    "    data.loc[filtro_2,\"review_title_body_lemma\"] = data.loc[filtro_2,\"review_title_body_lemma\"].str.replace(palabra,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "given-satellite",
   "metadata": {
    "id": "9SUFV3Vhl_ap"
   },
   "outputs": [],
   "source": [
    "for palabra in remover_3:\n",
    "    data.loc[filtro_3,\"review_title_body_lemma\"] = data.loc[filtro_3,\"review_title_body_lemma\"].str.replace(palabra,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "christian-charm",
   "metadata": {
    "id": "6QJK6HA4mLZV"
   },
   "outputs": [],
   "source": [
    "for palabra in remover_4:\n",
    "    data.loc[filtro_4,\"review_title_body_lemma\"] = data.loc[filtro_4,\"review_title_body_lemma\"].str.replace(palabra,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "choice-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data['review_title_body_lemma'])\n",
    "y = np.array(data['stars'])\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "xtest, xdev, ytest, ydev = train_test_split(xtest,ytest,test_size=0.5,random_state=42,stratify=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reliable-squad",
   "metadata": {
    "id": "DRvMnv0f_dFG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-therapy",
   "metadata": {
    "id": "wwHuZC35_ggC"
   },
   "outputs": [],
   "source": [
    "num_palabras = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-treasure",
   "metadata": {
    "id": "8undfyxTs6ys"
   },
   "source": [
    "Voy a instanciar la clase Tokenizer para extraer el vocabulario y despues reemplazar las palabras por tokens en todos los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-klein",
   "metadata": {
    "id": "GfqtZLh6rJJ_"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-tablet",
   "metadata": {
    "id": "srSCiNNktxE7"
   },
   "source": [
    "Considero extraer el vocabularia del conjunto de entrenamiento porque si lo hago con todo el corpus, el vocabulario podria incluir palabras que despues no aparezcan en el conjunto de entrenamiento, y algunas palabras serian ignoradas, siendo mas concreto, se perderia informacion para el entrenamiento. Ademas, el conjunto de entrenamiento es de 200000 textos (el 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-preliminary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5NfnKQZrP8Z",
    "outputId": "98f14645-179d-4ac2-e212-6d732168ec92"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(xtrain) #Graba un vocabulario de 10000 palabras donde cada palabra esta asociada a un token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-world",
   "metadata": {
    "id": "cI_oSj6LvZC6"
   },
   "source": [
    "Ahora voy a transformar los textos a tokens a partir del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-vatican",
   "metadata": {
    "id": "mDQCMHJjrf1l"
   },
   "outputs": [],
   "source": [
    "xtrain_tokens = tokenizer.texts_to_sequences(xtrain) #Transforma los cada texto del corpus en base al vocabulario\n",
    "xtest_tokens = tokenizer.texts_to_sequences(xtest)\n",
    "xdev_tokens = tokenizer.texts_to_sequences(xdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-origin",
   "metadata": {
    "id": "ikqugQ9TrxuU"
   },
   "source": [
    "Cantidad de tokens en cada secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-bahamas",
   "metadata": {
    "id": "i5TIb3dkrw9c"
   },
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in xtrain_tokens + xtest_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-transsexual",
   "metadata": {
    "id": "tVO8wGxfr3LB"
   },
   "source": [
    "Voy a definir un numero maximo de tokens para las secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-telling",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7w8jCU8IsA_3",
    "outputId": "39a11153-505e-458a-de34-7b22666488ba"
   },
   "outputs": [],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-aquarium",
   "metadata": {
    "id": "Iwf25PyevqN9"
   },
   "source": [
    "**tf.keras.preprocessing.sequence.pad_sequences** se encarga de ajustar todas los arreglos de tokens en una dimension especifica.\n",
    "\n",
    "Por ejemplo, si yo tengo este arreglo:\n",
    "\n",
    "[[1], [2, 3], [4, 5, 6]]\n",
    "\n",
    "y quiero que todas las filas tengan la misma dimension, tendria que ejecutar esto:\n",
    "\n",
    "sequence = [[1], [2, 3], [4, 5, 6]];\n",
    "\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence)\n",
    "\n",
    "Resultado:\n",
    "\n",
    "[\n",
    "\n",
    "  [0, 0, 1], \n",
    "\n",
    "  [0, 2, 3], \n",
    "\n",
    "  [4, 5, 6]\n",
    "\n",
    "]\n",
    "\n",
    "rellena los espacios vacios con ceros y trunca las filas cuya dimension es mayor a la maxima empezando por la derecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-bermuda",
   "metadata": {
    "id": "AR-gHy7WsQI4"
   },
   "outputs": [],
   "source": [
    "pad = 'pre'\n",
    "xtrain_pad = pad_sequences(xtrain_tokens, maxlen=max_tokens,padding=pad, truncating=pad)\n",
    "xtest_pad = pad_sequences(xtest_tokens, maxlen=max_tokens,padding=pad, truncating=pad)\n",
    "xdev_pad = pad_sequences(xdev_tokens, maxlen=max_tokens,padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-numbers",
   "metadata": {
    "id": "ya5YYP_JwE5t"
   },
   "source": [
    "# **Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-mambo",
   "metadata": {
    "id": "RFvJt97vwS6H"
   },
   "source": [
    "El primer prototipo sera una red neuronal recurrente para clasificar textos de multiclases.\n",
    "\n",
    "Las RNN estan capacitadas para reconocer patrones en datos secuenciales como por ejemplo: los textos.\n",
    "\n",
    "El dataset de la problematica tiene una particularidad, las palabras positivas como \"bueno\" y \"calidad\" aparecen dentro de todas las clases (en la 1, 2, 3, 4 y 5), es decir, no podemos guiarnos por palabras claves para hacer la clasificacion, el modelo tiene que procesar secuencias de palabras y las RNN se enfocan precisamente en eso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-equipment",
   "metadata": {
    "id": "UXmUr-CArPTZ"
   },
   "source": [
    "**Estrucutra del modelo**\n",
    "\n",
    "La estructura es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-highland",
   "metadata": {
    "id": "krWm5zQFrX37"
   },
   "outputs": [],
   "source": [
    "model = Sequential() #Modelo de capas secuenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-family",
   "metadata": {
    "id": "jaBm4xCpraHk"
   },
   "outputs": [],
   "source": [
    "embedding_size = 8 #Tamaño de vectores de salida de la capa de incrustacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-shell",
   "metadata": {
    "id": "lQGBNPhmrnCU"
   },
   "source": [
    "**Capa de incrustacion (embedding)**\n",
    "\n",
    "Los tokens estan en un rango de 1 - 10000, el RNN no puede trabajar con valores tan amplios.\n",
    "\n",
    "Entones lo que se hace es transformar los tokens en vectores (en este caso de longitud 8), los numeros en los vectores varian entre -1 y 1\n",
    "\n",
    "Como esta es la primera capa del RNN, su dimension sera igual al maximo numero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-newport",
   "metadata": {
    "id": "EQ-5qnplruq0"
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_palabras,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='Capa_incrustacion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-vault",
   "metadata": {
    "id": "hxmLplXqrx88"
   },
   "source": [
    "**Unidad recurrente oculta (GRU)**\n",
    "\n",
    "Estas unidades aseguran mantener en memoria la informacion importantes de las entradas y resuelven el problema de la desaparicion del gradiente que ocurre cuando se actualizan las unidades ocultas sin importar su relevancia, y por ende la function tanh reduce las actualizaciones hasta un punto cercano a cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-assistant",
   "metadata": {
    "id": "gfq1oY9Er3Ie"
   },
   "outputs": [],
   "source": [
    "model.add(GRU(units=16, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-strain",
   "metadata": {
    "id": "_m2x11rnr43c"
   },
   "outputs": [],
   "source": [
    "model.add(GRU(units=8, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-expression",
   "metadata": {
    "id": "skCq5i05r64S"
   },
   "outputs": [],
   "source": [
    "model.add(GRU(units=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-second",
   "metadata": {
    "id": "qDB9WCCDum7v"
   },
   "source": [
    "**Capa dense**\n",
    "\n",
    "La capa Dense junto con la activacion \"relu\", permiten que la red neuronal pueda aumentar su performance, acelerar el aprendizaje y evitar la desaparicion del gradiente (porque la activacion relu reemplaza los pesos negativos por cero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-privacy",
   "metadata": {
    "id": "QltVB9XxsHBg"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(16, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-fever",
   "metadata": {
    "id": "ITXW1wBnyOZ4"
   },
   "source": [
    "**Capa de salida**\n",
    "\n",
    "Devuelve un arreglo de 5 elementos, donde cada elemento se considera como la probabilidad de pertenecer a una clase en particular. Para concluir la prediccion voy a tomar la clase con mayor probabilidad de pertenencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-guitar",
   "metadata": {
    "id": "MioeHiwBsJVc"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-ecuador",
   "metadata": {
    "id": "Bnqljzr5yz1Z"
   },
   "source": [
    "**Metrica de evaluacion**\n",
    "\n",
    "Voy a usar el accuracy score porque la consigna es predecir las mismas clases que contiene la variable objetivo en los datasets.\n",
    "\n",
    "Sin embargo, durante el desarrollo voy a usar matrices de confusion para ver como se comporta el modelo al predecir y tambien para encontrar errores de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "italic-badge",
   "metadata": {
    "id": "B6zEVsUr4jfg"
   },
   "outputs": [],
   "source": [
    "ytrain_cat = tf.keras.utils.to_categorical(ytrain, num_classes=6)\n",
    "ytest_cat = tf.keras.utils.to_categorical(ytest, num_classes=6)\n",
    "ydev_cat = tf.keras.utils.to_categorical(ydev, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-recall",
   "metadata": {
    "id": "hV-IxAfM5BWp"
   },
   "outputs": [],
   "source": [
    "ytrain_cat = np.delete(ytrain_cat,0,axis=1)\n",
    "ytest_cat = np.delete(ytest_cat,0,axis=1)\n",
    "ydev_cat = np.delete(ydev_cat,0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reverse-holiday",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtBBMy005Res",
    "outputId": "fb0898b7-7b51-48c0-96fc-565ad4cd23d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (167995, 5)\n",
      "Test shape: (20999, 5)\n",
      "Dev shape: (21000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\",ytrain_cat.shape)\n",
    "print(\"Test shape:\",ytest_cat.shape)\n",
    "print(\"Dev shape:\",ydev_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-judgment",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYSRFiGB4BZB",
    "outputId": "b27cf7b2-9a70-44e1-d0de-ce9dd4b7b03f"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "modelo = Sequential(name=\"Modelo\")\n",
    "\n",
    "embedding_size = 8\n",
    "\n",
    "modelo.add(Embedding(input_dim=num_palabras,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='Capa_incrustacion'))\n",
    "\n",
    "modelo.add(GRU(units=16, return_sequences=True))\n",
    "\n",
    "modelo.add(GRU(units=8, return_sequences=True))\n",
    "\n",
    "modelo.add(GRU(units=4))\n",
    "\n",
    "modelo.add(Dense(16, activation='relu'))\n",
    "\n",
    "modelo.add(Dense(5, activation='softmax'))\n",
    "\n",
    "modelo.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-tuning",
   "metadata": {
    "id": "RjI6bmsh-IZZ"
   },
   "outputs": [],
   "source": [
    "filepath = 'rnn1.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-ontario",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhZE0yyMutOQ",
    "outputId": "3ced3569-1a49-4f34-b974-249dd72897d4"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "historial_entrenamiento = modelo.fit(xtrain_pad, ytrain_cat, validation_data=(xdev_pad, ydev_cat), epochs=15, callbacks = callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-robin",
   "metadata": {},
   "source": [
    "### Prueba del siguiente tutorial:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spiritual-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import random\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "political-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sorted-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((xtrain, ytrain_cat))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((xtest, ytest_cat))\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices((xdev, ydev_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suited-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0. 0. 0. 0. 1.]\n",
      "5 [0. 0. 0. 0. 1.]\n",
      "4 [0. 0. 0. 1. 0.]\n",
      "2 [0. 1. 0. 0. 0.]\n",
      "1 [1. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 1.]\n",
      "2 [0. 1. 0. 0. 0.]\n",
      "4 [0. 0. 0. 1. 0.]\n",
      "3 [0. 0. 1. 0. 0.]\n",
      "5 [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "indexes = random.sample(range(0, len(ytrain)), 10)\n",
    "\n",
    "for i in indexes:\n",
    "    print(ytrain[i], ytrain_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "after-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_dataset)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "furnished-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lesbian-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'o  pratico o  uni\\xc3\\xb3n pieza'\n",
      " b' movil bater\\xc3\\xada aguantar a\\xc3\\xb1o c\\xc3\\xa1mara \\xc3\\xadsimo foto noche misi\\xc3\\xb3n imposible'\n",
      " b'cruz beb bonito demasiado peque\\xc3\\xb1o ni\\xc3\\xb1o beb']\n",
      "\n",
      "labels:  [[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-deposit",
   "metadata": {},
   "source": [
    "## Create the text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deadly-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wound-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'buen', 'bien', 'calidad', 'precio', 'perfecto',\n",
       "       'nada', 'venir', 'pequeño', 'comprar', 'cumplir', 'llegar',\n",
       "       'recomeir', 'sin', 'compra', 'bonito', 'funcionar', 'mucho', 'o'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mexican-outdoors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 58)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "capital-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'o  pratico o  uni\\xc3\\xb3n pieza'\n",
      "Round-trip:  o [UNK] o unión pieza                                                     \n",
      "\n",
      "Original:  b' movil bater\\xc3\\xada aguantar a\\xc3\\xb1o c\\xc3\\xa1mara \\xc3\\xadsimo foto noche misi\\xc3\\xb3n imposible'\n",
      "Round-trip:  movil batería aguantar año cámara ísimo foto noche misión imposible                                                \n",
      "\n",
      "Original:  b'cruz beb bonito demasiado peque\\xc3\\xb1o ni\\xc3\\xb1o beb'\n",
      "Round-trip:  cruz beb bonito demasiado pequeño niño beb                                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "opening-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bizarre-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "decent-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19564681 0.19904642 0.19959317 0.20313898 0.20257466]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tamil-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19564681 0.19904642 0.19959317 0.20313898 0.20257466]\n"
     ]
    }
   ],
   "source": [
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "several-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "nuclear-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 432,549\n",
      "Trainable params: 432,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "killing-symposium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2625/2625 [==============================] - 602s 224ms/step - loss: 1.2713 - accuracy: 0.4227 - val_loss: 0.8711 - val_accuracy: 0.5776\n",
      "Epoch 2/10\n",
      "2625/2625 [==============================] - 578s 220ms/step - loss: 0.8337 - accuracy: 0.5937 - val_loss: 0.8194 - val_accuracy: 0.6208\n",
      "Epoch 3/10\n",
      "2625/2625 [==============================] - 595s 227ms/step - loss: 0.7876 - accuracy: 0.6243 - val_loss: 0.8067 - val_accuracy: 0.6318\n",
      "Epoch 4/10\n",
      "2625/2625 [==============================] - 578s 220ms/step - loss: 0.7620 - accuracy: 0.6427 - val_loss: 0.7884 - val_accuracy: 0.6438\n",
      "Epoch 5/10\n",
      "2625/2625 [==============================] - 949s 362ms/step - loss: 0.7385 - accuracy: 0.6584 - val_loss: 0.7755 - val_accuracy: 0.6630\n",
      "Epoch 6/10\n",
      "2625/2625 [==============================] - 1092s 416ms/step - loss: 0.7284 - accuracy: 0.6653 - val_loss: 0.7850 - val_accuracy: 0.6552\n",
      "Epoch 7/10\n",
      " 283/2625 [==>...........................] - ETA: 13:52 - loss: 0.7113 - accuracy: 0.6807"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ceb5f272ecaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit(train_dataset, epochs=10,\n\u001b[0;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     validation_steps=30)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
